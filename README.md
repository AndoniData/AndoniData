<h1 align="center">
  <img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&weight=500&size=28&duration=3000&pause=1000&color=00F5D4&center=true&vCenter=true&width=650&lines=Hi+%F0%9F%91%8B+I'm+Andoni+Lagos;Data+Specialist+%E2%86%92+Data+Engineer;Data+Engineering+%7C+Web+Scraping+%7C+Automation" alt="Typing SVG" />
</h1>

---

## ğŸš€ My Data Engineer Journey

Iâ€™m on an exciting path evolving from a **Data Specialist** into a proficient **Data Engineer**, focused on building scalable, maintainable data infrastructure that empowers businesses.

Hereâ€™s a summary of my journey â€” a combination of skills, projects, and learning steps shaping my transformation:

---

### ğŸ” Step 1: Strong Data Foundations  
- Mastering data extraction and cleaning with **Python**, **SQL**, and **data wrangling libraries** like `Pandas` & `NumPy`.  
- Handling diverse file formats: `.csv`, `.json`, `.parquet`, and web data (HTML, CSS).  
- Building automation and stablish bases with **Selenium**, **Requests**, **CCFI**, **Asyncio** and more! for reliable web scraping projects.
- Data Modeling with **SQL** based on DDL views and CTEs management
---

### âš™ï¸ Step 2: Building Automated Pipelines  
- Developing ETL pipelines to ingest, transform, and load data efficiently.  
- Implementing process control with **logging**, **timers**, and **error handling** to ensure pipeline reliability.  
- Working with databases like **PostgreSQL** for structured storage and retrieval.

---

### â˜ï¸ Step 3: Transitioning to Cloud-Native Solutions  
- Currently expanding expertise in **Google Cloud Platform** services:  
  - **BigQuery** for scalable analytics  
  - **Google Cloud Storage (GCS)** for data lakes  
  - **Dataproc** for managed Spark clusters  
- Containerizing workflows using **Docker** and orchestrating jobs with **Apache Airflow** (DAGs).

---

### ğŸ”® Step 4: Exploring Advanced Tools & Emerging Tech  
- Experimenting with frameworks like **Playwright**, **NoDriver** and undectable browser like camoufox for faster scraping automation.  
- Integrating **Large Language Models (LLMs)** and APIs to enhance data workflows and insights.  
- Preparing to implement real-time data pipelines for cryptocurrency, retail and real state analytics.

---

### ğŸ“‚ Projects Highlighting My Journey  

| Project | Description | Tech |
|---------|-------------|------|
| [**Retail Data Scraper - Falabella**](#) | Dynamic data extraction combining `Selenium` & `Requests` to scrape product and pricing data | `Python` `Selenium` `Requests` |
| [**ETL Pipeline for Analytics in Real State**](#) | (In Progress) Automated data ingestion and transformation pipeline feeding BI dashboards | `Airflow` `Pandas` `SQL` |
| [**Bitcoin Real-Time ETL**](#) | (In Progress) Streaming pipeline for real-time cryptocurrency data analysis | `Kafka` `Spark Streaming` `BigQuery` |

---

## ğŸ’» Tech Stack Summary

ğŸ”§ **Tools:** Python Â· SQL Â· Git Â· Linux (Ubuntu/Debian) Â· PostgreSQL Â· Logging & Timers Â· Jira Service Management
â˜ **Cloud:** GCP (BigQuery Â· GCS Â· Dataproc) *(transitioning)*  
ğŸ“Š **BI Tools:** Power BI Â· Apache Superset Â· Looker Studio  
ğŸ“š **Frameworks:** Pandas Â· NumPy Â· DuckDB Â· Selenium Â· Apache Spark Â· PyArrow  
ğŸ›  **Technologies:** DDL Â· Data Modeling  
ğŸ¢ **Systems:** SAP S/4HANA Â· SAP Datasphere *(legacy)*  
ğŸ§  **Skills:** OOP Â· Conceptual & business logical Data Modeling Â· Legacy Systems  
ğŸŒ± **Learning:** Playwright Â· Docker Â· Airflow Â· LLM Tools & API Integration  Â· GCP Environment
ğŸ“¦ **File Types:** .parquet Â· .csv Â· .json Â· HTML Â· CSS  
ğŸ’» **Local Dev:** `uv` Â· `venv`  

---

## ğŸ“« Connect & Collaborate

<p align="center">
  <a href="https://www.linkedin.com/in/andoni-lagos/" target="_blank">
    <img src="https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white"/>
  </a>
  <a href="https://github.com/AndoniData" target="_blank">
    <img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white"/>
  </a>
  <a href="#" target="_blank">
    <img src="https://img.shields.io/badge/Portfolio-000000?style=for-the-badge&logo=About.me&logoColor=white"/>
  </a>
</p>

---

â­ _Always open to collaborating on data engineering, pipeline automation, and scalable data solutions!_

<!---
AndoniData/AndoniData is a âœ¨ special âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
